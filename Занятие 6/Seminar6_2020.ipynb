{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Больше практики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытаемся ответить на вопрос, что делать, если качество модели нас не устраивает?\n",
    "\n",
    "Есть несколько путей решения:\n",
    "\n",
    "a) добавить признаков\n",
    "\n",
    "б) добавить данных\n",
    "\n",
    "в) усложнить/упростить модель\n",
    "\n",
    "Изначально не очевидно, какой (или какие) подходы позволят улучшить качество модели.\n",
    "\n",
    "Посмотрим на пример. Будем работать с данными по оттоку клиентов телеком-оператора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('telecom_churn.csv').drop('State', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте колонку International plan таким образом, чтобы вместо Yes в ней стояла 1, а вместо No - 0.\n",
    "\n",
    "Аналогичным образом преобразуйте колонку Voice mail plan.\n",
    "\n",
    "Затем преобразуйте значения колонки Churn (целевой столбец) в 1 (если True) и 0 (если False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте матрицу объект-признак из таблицы data и целевой вектор (data['Churn']), затем выкиньте из матрицы вектор 'Churn'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "y = ...\n",
    "X = ...\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед применением линейной модели **необходимо масштабировать признаки**. Создадим пайплайн, в котором сначала происходит масштабирование, а затем применяется модель. В данном случае будем использовать логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit_pipe = Pipeline([('scaler', StandardScaler()), \\\n",
    "                       ('logit', LogisticRegression(class_weight='balanced'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель (logit_pipe) по кросс-валидации и выведите на экран roc-auc (используйте функцию cross_val_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило, подбор гиперпараметров алгоритма улучшает его качество. Подберём значение параметра регуляризации C в логистической регрессии по кросс-валидации, используя GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'logit__C': np.logspace(-2, 0, 20)}\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logit.best_params_, grid_logit.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить модель путём добавления новых признаков. **Добавьте в модель все квадратичные признаки, используя функцию PolynomialFeatures**.\n",
    "\n",
    "Тогда происходит три действия: масштабирование, добавление признаков и применение модели. Объедините их в один пайплайн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "logit_pipe2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите значение параметра C по кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'logit__C': np.logspace(-2, 0, 20)}\n",
    "\n",
    "#your code here\n",
    "grid_logit2 = ...\n",
    "grid_logit2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logit2.best_params_, grid_logit2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Комментарии\n",
    "\n",
    "1. Ошибка на обучающей выборке сама по себе ничего не говорит о качестве модели\n",
    "\n",
    "2. Кросс-валидационная ошибка показывает, насколько хорошо модель подстраивается под данные (имеющийся тренд в данных), сохраняя при этом способность обобщения на новые данные\n",
    "\n",
    "3. В данной задаче качество модели улучшилось при добавлении квадратичных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применим метод K ближайших соседей для решения задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "cross_val_score(knn_model, X, y, cv=3, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите число соседей n_neighbors в методе с помощью GridSearchCV. Какое число соседей получилось оптимальным? Какое качество показал алгоритм на кросс-валидации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте квадратичных признаков в модель и создайте пайплайн из добавления признаков и применения метода KNN. Найдите оптимальное количество соседей по кросс-валидации. Какое количество соседей получилось в этой модели? Какое качество показал алгоритм на кросс-валидации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание.\n",
    "\n",
    "Примените метод опорных векторов для решения данной задачи. \n",
    "\n",
    "Используйте пайплайн, состоящий из масштабирования, извлечения квадратичных признаков и применения SVM.\n",
    "\n",
    "Вычислите качество алгоритма на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите значение параметра регуляризации C по кросс-валидации и нарисуйте валидационную кривую, отражающую качество в зависимости от C. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите на количество 0 и 1 в целевой переменной. Является ли выборка сбалансированной?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте в обученную выше последнюю версию логистической регрессии параметр **class_weight = 'balanced'**. Посмотрите на качество на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично - добавьте в модель SVM параметр class_weight = 'balanced' и выведите на экран качество алгоритма на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, улучшит ли качество применение SVM с ядром. Попробуйте использовать SVM с различными ядрами для данной задачи. \n",
    "\n",
    "Для каждого ядра подберите значение параметра C по кросс-валидации.\n",
    "\n",
    "Для наилучшего из алгоритмов выведите график learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модельную задачу регрессии. Объектами будут являться точки на плоскости (т.е. каждый объект описывается 2 признаками), целевая переменная — расстояние от объекта до точки (0, 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем вспомогательную функцию, которая будет возвращать решетку для дальнейшей красивой визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.random.normal(size=(100, 2))\n",
    "data_y = (data_x[:, 0] ** 2 + data_x[:, 1] ** 2) ** 0.5\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим дерево на сгенерированных данных и предскажем ответы для каждой точки решетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "xx, yy = get_grid(data_x)\n",
    "print(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "Сейчас мы сгенерировали 100 точек из нормального распределения и обучили решающее дерево на них. Сгенерируйте 300 точек из нормального распределения, обучите на них дерево и выведите на экран результат (как на картинке выше).\n",
    "\n",
    "Сгенерированные точки и расстояние до точек сохраните в массивы data_x300, data_y300, для обучения и предсказания используйте эти массивы.\n",
    "\n",
    "Улучшилось ли предсказание алгоритма на решётке? (т.е. стала ли раскраска всей плоскости более правильной?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернёмся к исходным данным (100 точек).\n",
    "\n",
    "Посмотрим как будут выглядеть разделяющая поверхность в зависимости от \n",
    "- минимального количества объектов в листе\n",
    "- максимальной глубины дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "for i, max_depth in enumerate([1, 2, 4, 6]):\n",
    "    for j, min_samples_leaf in enumerate([1, 5, 10, 15]):\n",
    "        clf = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        clf.fit(data_x, data_y)\n",
    "        xx, yy = get_grid(data_x)\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "        plt.subplot2grid((4, 4), (i, j))\n",
    "        plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='spring')\n",
    "        plt.title('max_depth=' + str(max_depth) + ', min_samples_leaf: ' + str(min_samples_leaf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Как влияет увеличение максимальной глубины и/или уменьшение минимального количества объектов выборки в листе на качество на обучающей выборке? на переобучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Неустойчивость решающих деревьев\n",
    "\n",
    "Решающие деревья — это алгоритмы, неустойчивые к изменениям обучающей выборки, т.е. при малейших её изменениях итоговый классификатор может радикально измениться.\n",
    "Посмотрим, как будет меняться структура дерева при обучении на разных 90%-х подвыборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(3):\n",
    "    clf = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    indices = np.random.randint(data_x.shape[0], size=int(data_x.shape[0] * 0.9))\n",
    "    clf.fit(data_x[indices], data_y[indices])\n",
    "    xx, yy = get_grid(data_x)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='winter')\n",
    "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество дерева в зависимости от параметров на одном из стандартных наборов данных - Бостонском датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- будем оценивать качество алгоритма по кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем зафиксировать разбиение на фолды, чтобы затем каждый раз использовать одно и то же разбиение при кросс-валидации, это полезно при сравнении алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cv = KFold(X.shape[0], shuffle=True, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите качество DecisionTreeRegressor, обученного на данных X, y по кросс-валидации. В функции cross_val_score в качестве cv поставьте cv=cv, в качестве метрики - 'neq_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "Метрика MSЕ имеет не ограничена сверху. Поэтому для оценки качества алгоритма можно также пользоваться метрикой R2 (коэффициент детерминации), так как он не превышает 1 (и чем ближе к 1, тем лучше).\n",
    "\n",
    "Выведите на экран значение R2 алгоритма ('r2')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения качества модели при различных наборах параметров или для сравнения моделей на одном датасете можно использовать, как и раньше, MSE.\n",
    "\n",
    "Будем подбирать параметры решающего дерева по сетке с целью увеличить качество алгоритма. Будем подбирать значения max_features и max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите по кросс-валидации оптимальные значения max_features и max_depth. В функции GridSearchCV в качестве cv поставьте заранее фиксированное разбиение (cv=cv), метрику качества используйте scoring='neq_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'max_features': [None, 'log2', 'sqrt'], \n",
    "        'max_depth': [2, 4, 6, 8, 10, 20, 50]},\n",
    "\n",
    "gs = GridSearchCV(DecisionTreeRegressor(), params, cv=3, n_jobs=-1)\n",
    "\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем на экран средние значения и стандартные отклонения, полученные при GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "Теперь попробуем одновременно подбирать значения max_features, max_depth и min_samples_leaf. Ищите min_samples_leaf в диапазоне от 1 до 20 с шагом 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как в данной задаче зависит качество алгоритма от количества параметров, которые мы оптимизируем?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "Поработайте с датасетом wine_data (в каждой строке этого датасета содержится информация о бутылках вина одного из трёх видов: в первой колонке - вид вина (1, 2 или 3), в колонках 1-13 - свойства вина). \n",
    "\n",
    "A. Решите задачу с помощью DecisionTreeClassifier:\n",
    "- подберите гиперпараметры алгоритма по кросс-валидации\n",
    "Что вы можете сказать об алгоритме? Он переобучился/недообучился/обучился как надо и вы довольны качеством?\n",
    "\n",
    "B. Попробуйте увеличить число признаков с помощью добавления полиномиальных признаков. Также можно добавить функции от признаков вручную (те, которые вам кажутся подходящими в данной задаче).\n",
    "Улучшилось ли качество алгоритма?\n",
    "\n",
    "C. Постройте матрицу корреляций признаков. Есть ли признаки, которые практически не коррелируют с целевой переменной? Попробуйте их удалить. Есть ли пары сильно коррелирующих между собой признаков? Удалите по одному признаку из каждой пары.\n",
    "Помогло ли это улучшить качество в данной задаче?\n",
    "\n",
    "Пункты B и C можно скомбинировать для достижения наилучшего качества.\n",
    "\n",
    "Далее попробуйте решить исходную задачу линейными методами. Не забудьте масштабировать данные перед применением этих методов:\n",
    "\n",
    "D. Решите исходную задачу с помощью логистической регрессии.\n",
    "\n",
    "E. Решите исходную задачу с помощью SVMClassifier с линейным и нелинейными ядрами.\n",
    "\n",
    "F. Решите исходную задачу с помощью наивного байесовского классификатора (https://scikit-learn.org/stable/modules/naive_bayes.html).\n",
    "\n",
    "G. Сделайте мини-отчет о проведенной работе. Для этого ответьте на вопросы:\n",
    "a) какой классификатор дал наилучший результат? чему равны значения метрик MSE и R2?\n",
    "\n",
    "b) какие новые признаки вы добавили и какие признаки удалили?\n",
    "\n",
    "c) удалось ли добиться того, что алгоритм не переобучился и не недообучился?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
