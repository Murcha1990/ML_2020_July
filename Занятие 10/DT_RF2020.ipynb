{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решающие деревья и решающие леса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Решающие деревья на искусственно сгенерированных данных.\n",
    "\n",
    "Рассмотрим модельную задачу регрессии. Объектами будут являться точки на плоскости (т.е. каждый объект описывается 2 признаками), целевая переменная — расстояние от объекта до точки (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем вспомогательную функцию, которая будет возвращать решетку для дальнейшей красивой визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.random.normal(size=(100, 2))\n",
    "data_y = (data_x[:, 0] ** 2 + data_x[:, 1] ** 2) ** 0.5\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим дерево на сгенерированных данных и предскажем ответы для каждой точки решетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "xx, yy = get_grid(data_x)\n",
    "print(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как будет выглядеть разделяющая поверхность в зависимости от \n",
    "- минимального количества объектов в листе\n",
    "- максимальной глубины дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "for i, max_depth in enumerate([1, 2, 4, 6]):\n",
    "    for j, min_samples_leaf in enumerate([1, 5, 10, 15]):\n",
    "        clf = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        clf.fit(data_x, data_y)\n",
    "        xx, yy = get_grid(data_x)\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "        plt.subplot2grid((4, 4), (i, j))\n",
    "        plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='spring')\n",
    "        plt.title('max_depth=' + str(max_depth) + ', min_samples_leaf: ' + str(min_samples_leaf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Как влияет увеличение максимальной глубины и/или уменьшение минимального количества объектов выборки в листе на качество на обучающей выборке? на переобучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неустойчивость решающих деревьев\n",
    "\n",
    "Решающие деревья — это алгоритмы, неустойчивые к изменениям обучающей выборки, т.е. при малейших её изменениях итоговый классификатор может радикально измениться.\n",
    "Посмотрим, как будет меняться структура дерева при обучении на разных 90%-х подвыборках.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(3):\n",
    "    clf = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    indices = np.random.randint(data_x.shape[0], size=int(data_x.shape[0] * 0.9))\n",
    "    clf.fit(data_x[indices], data_y[indices])\n",
    "    xx, yy = get_grid(data_x)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='winter')\n",
    "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Подбор параметров для решающего дерева в задаче Boston Houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество дерева в зависимости от параметров на одном из стандартных наборов данных - Бостонском датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = data.data\n",
    "y_full = data.target\n",
    "\n",
    "print(X_full[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- разобъём все данные на train и test\n",
    "- будем оценивать качество алгоритма по кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X_full, y_full, test_size=100, \n",
    "                                        random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cv = KFold(X.shape[0], shuffle=True, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regr = DecisionTreeRegressor(random_state=241)\n",
    "print(-cross_val_score(regr, X, y, cv=cv, \n",
    "                       scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика MSЕ имеет не ограничена сверху. Поэтому для оценки качества алгоритма можно также пользоваться метрикой R2 (коэффициент детерминации), так как он не превышает 1 (и чем ближе к 1, тем лучше).\n",
    "\n",
    "Выведем на экран значение R2 алгоритма ('r2')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(regr, X, y, cv=cv, \n",
    "                       scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения качества модели при различных наборах параметров или для сравнения моделей на одном датасете можно использовать, как и раньше, MSE.\n",
    "\n",
    "Будем подбирать параметры решающего дерева по сетке с целью увеличить качество алгоритма. Будем подбирать значения max_features и max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание. \n",
    "\n",
    "С помощью GridSearchCV подберите оптимальную глубину решающего дерева (max_depth) и количество признаков (max_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={'max_features': [None, 'log2', 'sqrt'], \n",
    "            'max_depth': #your code here}\n",
    "            \n",
    "gs = #your code here\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "Теперь попробуем одновременно подбирать значения max_features, max_depth и min_samples_leaf. Ищите min_samples_leaf в диапазоне range(1,20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid=#your code here\n",
    "gs = #your code here\n",
    "\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как в данной задаче зависит качество алгоритма от количества параметров, которые мы оптимизируем?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Решающий лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какое качество в задаче Boston Houses можно получить при использовании решающего леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor(max_depth = 8, min_samples_leaf = 9)\n",
    "t1 = time.time()\n",
    "print(-cross_val_score(regr, X, y, cv=cv,\n",
    "                       scoring='neg_mean_squared_error').mean())\n",
    "t2 = time.time()\n",
    "print('time:', t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите среднюю квадратичную ошибку на кросс-валидации для решающего леса с количеством деревьев n_estimators: 10, 100, 1000.\n",
    "\n",
    "*измерьте время обучения алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import time\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=#your code here)\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график качества классификации на кросс-валидации в зависимости от числа деревьев.\n",
    "\n",
    "На каждой итерации цикла обучаем регрессор командой regr = ... и добавляем в список Scores число cross_val_score:\n",
    "Scores.append(cross_val_score(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "Ntrees = np.arange(5,120,20)\n",
    "Scores = []\n",
    "\n",
    "for elem in tqdm(Ntrees):\n",
    "    regr = #your code here\n",
    "    Scores.append(#your code here)\n",
    "    \n",
    "plot(Scores)\n",
    "xlabel('number of trees', fontsize=18)\n",
    "ylabel('MSE', fontsize=16)\n",
    "xticks(arange(len(Ntrees)), Ntrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график количества времени, потраченного на обучение в зависимости от числа деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "Ntrees = np.arange(5,120,20)\n",
    "Times = []\n",
    "\n",
    "for elem in tqdm(Ntrees):\n",
    "    regr = RandomForestRegressor(n_estimators=elem)\n",
    "    t1 = time.time()\n",
    "    s = -cross_val_score(regr, X, y, cv=cv,\n",
    "                       scoring='neg_mean_squared_error').mean()\n",
    "    t2 = time.time()\n",
    "    Times.append(t2-t1)\n",
    "    \n",
    "plot(Times)\n",
    "xlabel('number of trees', fontsize=18)\n",
    "ylabel('time', fontsize=16)\n",
    "xticks(arange(len(Ntrees)), Ntrees)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
